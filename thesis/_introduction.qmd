# Introduction

## Project overview

Blender is a free, open-source 3D creation suite used for modeling, animation, effects, simulation, and rendering [@blender-manual; @soni2023blenderreview]. It powers professional production pipelines and is increasingly used in research, engineering, and higher education. Studies show that Blender’s Python architecture, open-source licensing, and advanced rendering capabilities make it suitable even for scientific and engineering workflows, such as generating synthetic digital image correlation images for computational experiments [@rohe2022syntheticdic]. Because Blender is both powerful and freely available, it is widely adopted by students, independent artists, and early-career creators building portfolios on limited budgets.

However, Blender’s strength comes with a cost: a steep learning curve. Prior analyses of Blender’s interface highlight how beginners struggle with its dense layout, multi-editor environment, and mode-dependent tool system [@soni2023blenderreview]. New users must manage concepts such as object versus mesh data, operator conventions, modifier order, shading settings, and Python-driven tools long before they can produce high-quality work. This can slow progress, reduce confidence, and limit the number of completed portfolio pieces.

This project introduces **Suzanne**, a Blender add-on that lives in the right-hand **N-panel** and provides short, numbered, in-viewport steps for common tasks. Instead of searching externally for guidance while working, users receive instructions directly beside the 3D Viewport. The goal is to reduce context switching, help users execute reliably, and increase the number of polished artifacts that students and independent artists can publish.

![Blender interface with key areas visible: 3D Viewport (center), Outliner (right), Properties (bottom-right), and the N-panel (right sidebar).](images/blender_ui.png){fig-cap="Figure 1. The Blender interface. Beginners juggle regions, modes, operators, and modifier order. Screenshot by the author." width=100%}

## Key terms and concepts (grounding the reader)

- **N-panel.** A vertical sidebar toggled with **N** in the 3D Viewport hosting add-ons and tools. Suzanne is located here to keep guidance directly inside the creative workspace [@blender-manual].

- **Mode.** Blender tools are mode-specific (e.g., Object Mode vs. Edit Mode). Many operators behave differently or are unavailable depending on the mode, making explicit mode requirements essential in step-by-step guidance [@blender-manual; @soni2023blenderreview].

- **Operator.** Any action invoked by menus, buttons, shortcuts, or the **F3** search. Naming operators (e.g., *Mesh > Normals > Recalculate Outside*) is key for reproducibility and structured documentation [@blender-manual].

- **Modifier stack.** A series of non-destructive operations whose **order** changes results. For example, applying Bevel before Subdivision Surface produces a different silhouette and shading than the reverse [@blender-manual].

- **Grounding.** Retrieval-Augmented Generation (RAG) combines large language models with authoritative sources. Integrating RAG ensures instructional steps match Blender’s official terminology and correct behavior [@gao2023retrieval].

## Motivation (why this matters for students and portfolios)

In my personal experience learning Blender over the past five years, most challenges involved “micro-execution”—not understanding the concept of what to do, but figuring out *which* operator to call, *what* mode to be in, and *what* order to perform actions. Research has shown that Blender’s growing scope and tool density can overwhelm newcomers and slow their learning process [@soni2023blenderreview]. Even small tasks such as beveling edges without shading artifacts or setting up lighting often require watching multiple tutorials or searching through forums.

Meanwhile, early-career 3D creators—students, hobbyists, and emerging artists—grow primarily through their **portfolios**. Recruiters and instructors evaluate:

- Clean topology visible in wireframe or clay renders  
- High-quality lighting and presentation  
- Turntables and breakdowns  
- UV layouts and readable materials  
- Clear process documentation

Students typically post these artifacts to ArtStation, Behance, GitHub Pages, or social media. However, producing consistent, high-quality work requires fluid execution, and execution is often slowed by searching for instructions outside the application.

Suzanne aims to address this gap: **deliver high-clarity, minimal-step instructions inside Blender**, grounded on authoritative documentation and consistent terminology.

This approach is supported by educational research showing that AI-based learning tools improve cognitive outcomes when instructional content is concise, context-specific, and directly actionable [@luo2025ailearningtools]. Suzanne follows these principles by placing guidance beside the active viewport and presenting it as small, verifiable steps that can be performed immediately.

## Problem statement (what gap this work addresses)

Blender learners lose time, motivation, and project momentum because most guidance lives **outside** the application, spread across long YouTube videos, scattered forum posts, or generic documentation. These sources are rarely tailored to the user’s current mode, object selection, or workflow context. As a result, beginners struggle with:

- Mode confusion  
- Misordered modifiers  
- Shading artifacts  
- Inconsistent steps from mixed-version tutorials  
- Difficulty reproducing actions from memory

The core gap is **micro-execution**: mode, operator, panel path, and modifier order.  
This project addresses that gap by building an in-viewport assistant that:

1. Returns verifiable steps inside the N-panel  
2. Grounds instructions on the official Blender Manual  
3. Uses retrieval techniques aligned with RAG best practices to maintain correctness [@gao2023retrieval]  
4. Supports small troubleshooting branches to handle common issues  

Because Blender is increasingly used in research and engineering [@rohe2022syntheticdic], reliable execution and clear documentation also support academic reproducibility.

## Project goals (what this thesis will deliver)

1. **Step-based teaching.** Provide concise, numbered instructions that reflect Blender’s operator names and panel paths, always stating prerequisites (mode, selection, object type).

2. **Documentation grounding.** Integrate retrieval over the Blender Manual to maintain terminology accuracy and consistency with Blender’s UI labels [@blender-manual; @gao2023retrieval].

3. **Learning iteration.** Support follow-ups like *next step*, *repeat this*, and corrective branches (e.g., faceting → Shade Smooth → Auto Smooth → Recalculate Normals).

4. **Optional code execution with guardrails.** Present small Python snippets that can be safely executed after user confirmation, leveraging Blender’s scripting environment [@rohe2022syntheticdic].

5. **Portfolio-driven defaults.** Provide guidance for modeling, lighting, and rendering workflows commonly used in portfolio pieces.

6. **Evaluation.** Compare Suzanne to baseline search-driven workflows for time-on-task, accuracy, and perceived usefulness.

## Assumptions, limitations, and delimitations

### **Assumptions**
- Users have Blender installed and can access the N-panel [@blender-manual].  
- Users consent to API usage when submitting text or audio for transcription.  
- English-language UI labels are acceptable in the initial release.

### **Limitations**
- LLM-generated steps may contain inaccuracies; grounding mitigates but does not eliminate this [@gao2023retrieval].  
- Code execution is restricted to a safe subset of Blender’s Python API.  
- Behavior may vary across Blender versions and hardware setups [@blender-manual].

### **Delimitations**
- Focus on learnability, modeling, shading, and presentation—not advanced rigging or simulation.  
- No microphone-based live transcription in v0.x.  
- No end-user analytics are collected; study participation is voluntary and anonymized.

## Ethical considerations (narrative)

### **Privacy and consent**
Submitted prompts and audio files are processed through a third-party API. Research shows that LLMs face serious risks related to privacy, data leakage, and unintended memorization of sensitive content [@daspaper2025llmsecurity]. Suzanne therefore stores API keys only locally, never logs prompt content, and provides explicit warnings about avoiding sensitive material.

### **Reliability and user control**
While grounding reduces errors, LLMs remain fallible. The project follows safe design principles informed by survey research showing that AI tools must include human oversight, transparency, and reversible actions to maintain user trust [@daspaper2025llmsecurity]. Suzanne displays steps before running code, shows the generated script, requires explicit confirmation, and uses Blender’s undo stack for recovery.

### **Bias and inclusivity**
Educational research on AI tools highlights the importance of clear, accessible feedback that supports diverse learners [@luo2025ailearningtools]. Suzanne’s instructions are intentionally concise, neutral, and reproducible, supporting students, self-taught artists, and non-native English speakers.

### **Cost transparency and outages**
LLM providers may change pricing or rate limits. Suzanne surfaces clear error messages and recommends fallback workflows grounded in Blender’s official practices [@blender-manual].

### **Security and scope**
Because unrestricted Python execution can cause harm, Suzanne restricts script generation to object creation, transforms, lights, cameras, and shader nodes—avoiding file operations or network calls. This aligns with security recommendations for limiting LLM-driven code execution and potential attack surfaces [@daspaper2025llmsecurity].

## What does *not* belong in the Introduction

Practical modeling recipes, shading fixes, or operator sequences should not be included here. These belong in **Methods** or an **Appendix**, where Suzanne’s generated steps can be presented clearly. The Introduction is focused on background, motivation, problem definition, goals, scope, and ethics.

## Chapter roadmap

The remainder of this thesis proceeds as follows:

- **Related Work** reviews Blender learning challenges, prior add-ons, AI tutoring systems, RAG-based grounding, and safe model usage.  
- **Methods** details the N-panel UI, retrieval pipeline, grounding strategy, and safe code execution model.  
- **Evaluation** presents the study design, tasks, metrics, and analysis.  
- **Discussion** interprets results and limitations.  
- **Future Work** explores multilingual support, richer scene graph awareness, and expanded tool-calling capabilities.
